{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c55fa8b3-ccc5-46f3-b2da-f7a0b649114f",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "!apt update && apt upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9828aa07-e799-4d0b-9ce4-b25c852bc614",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a326494-485e-4127-969f-e9cbf4fb2ef7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"archive.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3d7b5f1-b2fc-4e4d-ae0d-f3d03660853e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fdc6664-39cf-4c79-96b5-71cab3c3c4ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dir = 'train'\n",
        "val_dir = 'test'\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(48,48),\n",
        "        batch_size=64,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=(48,48),\n",
        "        batch_size=64,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd6302a7-c9f9-46dc-b421-0bbd4b535c8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "emotion_model = Sequential()\n",
        "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
        "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "emotion_model.add(Flatten())\n",
        "emotion_model.add(Dense(1024, activation='relu'))\n",
        "emotion_model.add(Dropout(0.5))\n",
        "emotion_model.add(Dense(7, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00600f3e-8cd3-4903-9c60-3a1053792e60",
      "metadata": {},
      "outputs": [],
      "source": [
        "emotion_model.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=0.0001),metrics=['accuracy'])\n",
        "emotion_model_info = emotion_model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=28709 // 64,\n",
        "        epochs=50,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=7178 // 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18b18802-f127-463d-924b-bea19399b630",
      "metadata": {},
      "outputs": [],
      "source": [
        "emotion_model.save('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fd2db6e-ac63-419b-8c02-82749c3a59c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "emotion_model = load_model('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "737a0c65-8ebe-4599-9d93-d9c6d1b90b30",
      "metadata": {},
      "outputs": [],
      "source": [
        "def emotion_analysis(emotions):\n",
        "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "    y_pos = np.arange(len(objects))\n",
        "\n",
        "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
        "    plt.xticks(y_pos, objects)\n",
        "    plt.ylabel('percentage')\n",
        "    plt.title('emotion')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fe35afa-aee8-40bc-b2da-30b7583e7fd7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='capture.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "          const div = document.createElement('div');\n",
        "          const capture = document.createElement('button');\n",
        "          capture.textContent = 'Capture';\n",
        "          div.appendChild(capture);\n",
        "\n",
        "          const video = document.createElement('video');\n",
        "          video.style.display = 'block';\n",
        "          const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "          document.body.appendChild(div);\n",
        "          div.appendChild(video);\n",
        "          video.srcObject = stream;\n",
        "          await video.play();\n",
        "\n",
        "          google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "          await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "          const canvas = document.createElement('canvas');\n",
        "          canvas.width = video.videoWidth;\n",
        "          canvas.height = video.videoHeight;\n",
        "          canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "          stream.getVideoTracks()[0].stop();\n",
        "          div.remove();\n",
        "          return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    if data is None:\n",
        "        raise ValueError(\"Failed to capture photo.\")\n",
        "\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "\n",
        "    return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0638c40-eb30-4c7b-b1a8-6a3528fd7428",
      "metadata": {},
      "outputs": [],
      "source": [
        "take_photo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f67f7788-6cc3-45a6-8bef-d8496abe59d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def facecrop(image):\n",
        "    facedata = '/content/haarcascade_frontalface_alt.xml'\n",
        "    cascade = cv2.CascadeClassifier(facedata)\n",
        "\n",
        "    img = cv2.imread(image)\n",
        "\n",
        "    try:\n",
        "\n",
        "        minisize = (img.shape[1],img.shape[0])\n",
        "        miniframe = cv2.resize(img, minisize)\n",
        "\n",
        "        faces = cascade.detectMultiScale(miniframe)\n",
        "\n",
        "        for f in faces:\n",
        "            x, y, w, h = [ v for v in f ]\n",
        "            cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
        "\n",
        "            sub_face = img[y:y+h, x:x+w]\n",
        "\n",
        "\n",
        "            cv2.imwrite('capture.jpg', sub_face)\n",
        "\n",
        "    except Exception as e:\n",
        "        print (e)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    facecrop('/content/capture.jpg')\n",
        "\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "file = '/content/capture.jpg'\n",
        "true_image = image.load_img(file)\n",
        "img = image.load_img(file, color_mode=\"grayscale\", target_size=(48, 48))\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis = 0)\n",
        "\n",
        "x /= 255\n",
        "\n",
        "custom = emotion_model.predict(x)\n",
        "emotion_analysis(custom[0])\n",
        "\n",
        "x = np.array(x, 'float32')\n",
        "x = x.reshape([48, 48]);\n",
        "\n",
        "\n",
        "plt.imshow(true_image)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

